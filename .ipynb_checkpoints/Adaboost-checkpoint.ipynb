{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS74 Homework 2\n",
    "Professor VS Subrahmanian  \n",
    "November 3, 2020  \n",
    "Angela Zhang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources Consulted\n",
    "* [Scikit Learn DecisionTreeClassifier](https://scikit-learn.org/stable/modules/tree.html)\n",
    "* [Scikit Learn GaussianNB](https://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "* [Scikit Learn Linear SVM](https://scikit-learn.org/stable/modules/svm.html)\n",
    "* [Categorical Encoding](https://pbpython.com/categorical-encoding.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as ply\n",
    "\n",
    "# decision trees, naive bayes, linear SVM\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# preprocessing data\n",
    "from sklearn.preprocessing import OrdinalEncoder, normalize, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# quality of classifiers\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleandata(csv_file) -> X, y for testing\n",
    "\n",
    "def cleandata(csv_file):\n",
    "    df = pd.read_csv(csv_file) # importing dataset\n",
    "    \n",
    "    df = df.drop(columns=['WindGustDir']) # dropping WindGustDir because of NaN\n",
    "    \n",
    "    # change RainToday and RainTomorrow to 0 and 1 for no and yes\n",
    "    noyes_d = {'No': -1, 'Yes': 1}\n",
    "    df['RainTomorrow'] = df['RainTomorrow'].map(noyes_d).fillna(df['RainTomorrow'])\n",
    "    df['RainToday'] = df['RainToday'].map(noyes_d).fillna(df['RainToday'])\n",
    "    \n",
    "    wind_dict = {\n",
    "        \"0\": 0,\n",
    "        \"E\": 1,\n",
    "        \"ENE\": 2,\n",
    "        \"ESE\": 3,\n",
    "        \"N\": 4,\n",
    "        \"NE\": 5,\n",
    "        \"NNE\": 6,\n",
    "        \"NNW\": 7,\n",
    "        \"NW\": 8,\n",
    "        \"S\": 9,\n",
    "        \"SE\": 10,\n",
    "        \"SSE\": 11,\n",
    "        \"SSW\": 12,\n",
    "        \"SW\": 13,\n",
    "        \"W\": 14,\n",
    "        \"WNW\": 15,\n",
    "        \"WSW\": 16,\n",
    "    }\n",
    "    # Replace Wind Directions with Numbers from wind_dict\n",
    "    df['WindDir9am'] = df['WindDir9am'].map(wind_dict).fillna(df['WindDir9am'])\n",
    "    df['WindDir3pm'] = df['WindDir3pm'].map(wind_dict).fillna(df['WindDir3pm'])\n",
    "    \n",
    "    # normalize data\n",
    "    column_names_to_not_normalize = ['RainToday', 'RainTomorrow']\n",
    "    column_names_to_normalize = [x for x in list(df) if x not in column_names_to_not_normalize ]\n",
    "    x = df[column_names_to_normalize].values\n",
    "    x_scaled = MinMaxScaler().fit_transform(x)\n",
    "    df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = df.index)\n",
    "    df[column_names_to_normalize] = df_temp\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.626812</td>\n",
       "      <td>0.534934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.984886</td>\n",
       "      <td>0.983023</td>\n",
       "      <td>0.553425</td>\n",
       "      <td>0.539150</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.442029</td>\n",
       "      <td>0.456332</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.987197</td>\n",
       "      <td>0.985435</td>\n",
       "      <td>0.372603</td>\n",
       "      <td>0.460850</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.728261</td>\n",
       "      <td>0.589520</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.447917</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.973046</td>\n",
       "      <td>0.972798</td>\n",
       "      <td>0.638356</td>\n",
       "      <td>0.592841</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.344203</td>\n",
       "      <td>0.414847</td>\n",
       "      <td>0.197441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.978437</td>\n",
       "      <td>0.978200</td>\n",
       "      <td>0.386301</td>\n",
       "      <td>0.409396</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.829710</td>\n",
       "      <td>0.617904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.978340</td>\n",
       "      <td>0.976367</td>\n",
       "      <td>0.679452</td>\n",
       "      <td>0.606264</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>0.909420</td>\n",
       "      <td>0.818777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.973238</td>\n",
       "      <td>0.974149</td>\n",
       "      <td>0.838356</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>0.789855</td>\n",
       "      <td>0.598253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.975452</td>\n",
       "      <td>0.976174</td>\n",
       "      <td>0.652055</td>\n",
       "      <td>0.563758</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>0.634058</td>\n",
       "      <td>0.613537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.967174</td>\n",
       "      <td>0.970869</td>\n",
       "      <td>0.701370</td>\n",
       "      <td>0.514541</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>0.373188</td>\n",
       "      <td>0.375546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.979496</td>\n",
       "      <td>0.981673</td>\n",
       "      <td>0.309589</td>\n",
       "      <td>0.375839</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.709607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364583</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.965922</td>\n",
       "      <td>0.967686</td>\n",
       "      <td>0.786301</td>\n",
       "      <td>0.653244</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MinTemp   MaxTemp  Rainfall  WindGustSpeed  WindDir9am  WindDir3pm  \\\n",
       "0     0.626812  0.534934  0.000000       0.312500      0.8750      0.3125   \n",
       "1     0.442029  0.456332  0.003656       0.270833      0.8750      0.3750   \n",
       "2     0.728261  0.589520  0.001828       0.447917      0.1250      0.3125   \n",
       "3     0.344203  0.414847  0.197441       0.000000      0.8750      0.1875   \n",
       "4     0.829710  0.617904  0.000000       0.000000      0.1875      0.3125   \n",
       "...        ...       ...       ...            ...         ...         ...   \n",
       "2495  0.909420  0.818777  0.000000       0.729167      0.6875      0.7500   \n",
       "2496  0.789855  0.598253  0.000000       0.250000      0.8750      0.1250   \n",
       "2497  0.634058  0.613537  0.000000       0.812500      0.2500      0.9375   \n",
       "2498  0.373188  0.375546  0.000000       0.000000      0.8750      0.7500   \n",
       "2499  0.891304  0.709607  0.000000       0.364583      0.4375      0.1875   \n",
       "\n",
       "      WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  Pressure9am  \\\n",
       "0         0.195652      0.228070         0.79     0.718750     0.984886   \n",
       "1         0.434783      0.228070         0.78     0.541667     0.987197   \n",
       "2         0.195652      0.385965         0.78     0.645833     0.973046   \n",
       "3         0.326087      0.263158         0.69     0.531250     0.978437   \n",
       "4         0.086957      0.421053         0.79     0.656250     0.978340   \n",
       "...            ...           ...          ...          ...          ...   \n",
       "2495      0.239130      0.421053         0.58     0.562500     0.973238   \n",
       "2496      0.130435      0.157895         0.70     0.708333     0.975452   \n",
       "2497      0.478261      0.754386         0.31     0.208333     0.967174   \n",
       "2498      0.565217      0.228070         0.48     0.312500     0.979496   \n",
       "2499      0.043478      0.385965         0.59     0.541667     0.965922   \n",
       "\n",
       "      Pressure3pm   Temp9am   Temp3pm RainToday  RainTomorrow  \n",
       "0        0.983023  0.553425  0.539150        -1            -1  \n",
       "1        0.985435  0.372603  0.460850        -1            -1  \n",
       "2        0.972798  0.638356  0.592841        -1            -1  \n",
       "3        0.978200  0.386301  0.409396         1            -1  \n",
       "4        0.976367  0.679452  0.606264        -1            -1  \n",
       "...           ...       ...       ...       ...           ...  \n",
       "2495     0.974149  0.838356  0.751678        -1            -1  \n",
       "2496     0.976174  0.652055  0.563758        -1            -1  \n",
       "2497     0.970869  0.701370  0.514541        -1            -1  \n",
       "2498     0.981673  0.309589  0.375839        -1            -1  \n",
       "2499     0.967686  0.786301  0.653244        -1            -1  \n",
       "\n",
       "[2500 rows x 16 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the df for Classifiers\n",
    "df = cleandata(\"./Weather.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers without AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the data\n",
    "X = df.drop('RainTomorrow', axis=1)\n",
    "y = df['RainTomorrow']\n",
    "\n",
    "# oversampling using SMOTE\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 using 10-fold: 0.7431405317279745\n"
     ]
    }
   ],
   "source": [
    "# Naïve Bayes without Boosting\n",
    "gnb = GaussianNB()\n",
    "sc_gnb = cross_val_score(gnb, X, y, scoring='f1_weighted', cv=10)\n",
    "total_f1_gnb = sum(sc_gnb)\n",
    "print(\"f1 using 10-fold: \" + str(total_f1_gnb/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 using 10-fold: 0.805616888033765\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree without Boosting\n",
    "dt = DecisionTreeClassifier()\n",
    "sc_dt = cross_val_score(dt, X, y, scoring='f1_weighted', cv=10)\n",
    "total_f1_dt = sum(sc_dt)\n",
    "print(\"f1 using 10-fold: \" + str(total_f1_dt/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.7668499726881457\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM without Boosting\n",
    "svc = LinearSVC()\n",
    "sc_svc = cross_val_score(svc, X, y, scoring='f1_weighted', cv=10)\n",
    "total_f1_gnb = sum(sc_svc)\n",
    "print(\"f1: \" + str(total_f1_gnb/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleandata(csv_file) -> X, y for testing\n",
    "# slight changes to csv cleandata function for test data\n",
    "\n",
    "def cleantestdata(csv_file):\n",
    "    df = pd.read_csv(csv_file) # importing dataset\n",
    "    \n",
    "    df = df.drop(columns=['WindGustDir']) # dropping WindGustDir because of NaN\n",
    "    \n",
    "    # change RainToday and RainTomorrow to 0 and 1 for no and yes\n",
    "    noyes_d = {'No': -1, 'Yes': 1}\n",
    "    df['RainToday'] = df['RainToday'].map(noyes_d).fillna(df['RainToday'])\n",
    "    \n",
    "    wind_dict = {\n",
    "        \"0\": 0,\n",
    "        \"E\": 1,\n",
    "        \"ENE\": 2,\n",
    "        \"ESE\": 3,\n",
    "        \"N\": 4,\n",
    "        \"NE\": 5,\n",
    "        \"NNE\": 6,\n",
    "        \"NNW\": 7,\n",
    "        \"NW\": 8,\n",
    "        \"S\": 9,\n",
    "        \"SE\": 10,\n",
    "        \"SSE\": 11,\n",
    "        \"SSW\": 12,\n",
    "        \"SW\": 13,\n",
    "        \"W\": 14,\n",
    "        \"WNW\": 15,\n",
    "        \"WSW\": 16,\n",
    "    }\n",
    "    # Replace Wind Directions with Numbers from wind_dict\n",
    "    df['WindDir9am'] = df['WindDir9am'].map(wind_dict).fillna(df['WindDir9am'])\n",
    "    df['WindDir3pm'] = df['WindDir3pm'].map(wind_dict).fillna(df['WindDir3pm'])\n",
    "    \n",
    "    # normalize data\n",
    "    column_names_to_not_normalize = ['RainToday']\n",
    "    column_names_to_normalize = [x for x in list(df) if x not in column_names_to_not_normalize ]\n",
    "    x = df[column_names_to_normalize].values\n",
    "    x_scaled = MinMaxScaler().fit_transform(x)\n",
    "    df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = df.index)\n",
    "    df[column_names_to_normalize] = df_temp\n",
    "    \n",
    "    X = df.drop('RainTomorrow', axis=1)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    def __init__(self, classifier):\n",
    "        self.classifier = classifier\n",
    "        self.classifiers = []\n",
    "        self.amount_of_say = []\n",
    "        self.weights = []\n",
    "        self.predictions = []\n",
    "\n",
    "    def set_weights(self, incorrect_rows, N):\n",
    "        aos = self.amount_of_say[-1]\n",
    "        for i in range(N):\n",
    "            if i in incorrect_rows:\n",
    "                self.weights[i] *= math.e**aos\n",
    "            else:\n",
    "                self.weights[i] *= (math.e**((-1) * aos))\n",
    "        sum_weights = sum(self.weights)\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] /= sum_weights # normalize sample weights to add up to 1\n",
    "    \n",
    "    def fit(self, df):\n",
    "        N = int(len(df) / 2) # sample size\n",
    "        self.weights = [1/len(df)]*len(df) # weights for all df\n",
    "        \n",
    "        for i in range(10):\n",
    "            # sample a training set using weights\n",
    "            ts = df.sample(n=N, weights=self.weights)\n",
    "\n",
    "            # learn a classifier\n",
    "            X_train = ts.drop('RainTomorrow', axis=1)\n",
    "            y_train = ts['RainTomorrow']\n",
    "\n",
    "            clf = self.classifier.fit(X_train, y_train)\n",
    "            predictions = clf.predict(df.drop('RainTomorrow', axis=1))\n",
    "            \n",
    "            y = df['RainTomorrow']\n",
    "\n",
    "            # total error\n",
    "            total_error = 0\n",
    "            incorrect_rows = []\n",
    "            for pred_ind in range(len(predictions)):\n",
    "                if predictions[pred_ind] != y[pred_ind]:\n",
    "                    total_error += self.weights[pred_ind]\n",
    "                    incorrect_rows.append(pred_ind)\n",
    "\n",
    "            # amount of say of classifier\n",
    "            amount_of_say = (math.log((1-total_error)/total_error))/2\n",
    "            self.classifiers.append(clf)\n",
    "            self.amount_of_say.append(amount_of_say)\n",
    "\n",
    "            # set weights accordingly\n",
    "            self.set_weights(incorrect_rows, N)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        ada_predictions = [0]*len(X)\n",
    "        for ind in range(len(self.classifiers)):\n",
    "            clf = self.classifiers[ind]\n",
    "            amount_of_say = self.amount_of_say[ind]\n",
    "            prediction = clf.predict(X)\n",
    "            for i in range(len(ada_predictions)):\n",
    "                ada_predictions[i] += (amount_of_say * prediction[i])\n",
    "        \n",
    "        for i in range(len(ada_predictions)):\n",
    "            ada_predictions[i] = 1 if ada_predictions[i] > 0 else -1\n",
    "        \n",
    "        self.predictions = ada_predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 for Adaboost with GNB: 0.8051834080777164\n",
      "Weighted F1 for Adaboost with DT: 0.8750117056243701\n",
      "Weighted F1 for Adaboost with SVC: 0.8211523256852066\n"
     ]
    }
   ],
   "source": [
    "# F1_weighted for Adaboost\n",
    "# Adaboost with GNB\n",
    "trn_gnb = GaussianNB()\n",
    "trn_gnb_adaboost = AdaBoost(trn_gnb)\n",
    "trn_gnb_adaboost.fit(df)\n",
    "trn_gnb_adaboost.predict(df.drop('RainTomorrow', axis=1))\n",
    "trn_gnb_ada_predictions = trn_gnb_adaboost.predictions\n",
    "gnb_ada_f1 = f1_score(y_true=df['RainTomorrow'], y_pred=trn_gnb_ada_predictions, average='weighted')\n",
    "print('Weighted F1 for Adaboost with GNB: ' + str(gnb_ada_f1))\n",
    "\n",
    "# Adaboost with DT\n",
    "trn_dt = DecisionTreeClassifier()\n",
    "trn_dt_adaboost = AdaBoost(trn_dt)\n",
    "trn_dt_adaboost.fit(df)\n",
    "trn_dt_adaboost.predict(df.drop('RainTomorrow', axis=1))\n",
    "trn_dt_ada_predictions = trn_dt_adaboost.predictions\n",
    "dt_ada_f1 = f1_score(y_true=df['RainTomorrow'], y_pred=trn_dt_ada_predictions, average='weighted')\n",
    "print('Weighted F1 for Adaboost with DT: ' + str(dt_ada_f1))\n",
    "\n",
    "# Adaboost with LinearSVM\n",
    "trn_svc = LinearSVC()\n",
    "trn_svc_adaboost = AdaBoost(trn_svc)\n",
    "trn_svc_adaboost.fit(df)\n",
    "trn_svc_adaboost.predict(df.drop('RainTomorrow', axis=1))\n",
    "trn_svc_ada_predictions = trn_svc_adaboost.predictions\n",
    "svc_ada_f1 = f1_score(y_true=df['RainTomorrow'], y_pred=trn_svc_ada_predictions, average='weighted')\n",
    "print('Weighted F1 for Adaboost with SVC: ' + str(svc_ada_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Prediction Generation (6 files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:373: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:374: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n"
     ]
    }
   ],
   "source": [
    "# using classifiers to generate predictions for test csv\n",
    "testX = cleantestdata(\"./weather_test.csv\")\n",
    "index_list = list(range(0, len(testX)))\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "gnb.fit(X, y)\n",
    "gnb_predictions = gnb.predict(testX)\n",
    "gnb_predictions_df = pd.DataFrame({'index': index_list, 'RainTomorrow': gnb_predictions})\n",
    "gnb_predictions_df.to_csv('gnb_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt.fit(X, y)\n",
    "dt_predictions = dt.predict(testX)\n",
    "dt_predictions_df = pd.DataFrame({'index': index_list, 'RainTomorrow': dt_predictions})\n",
    "dt_predictions_df.to_csv('dt_predictions.csv')\n",
    "\n",
    "# Linear SVM\n",
    "svc.fit(X, y)\n",
    "svc_predictions = svc.predict(testX)\n",
    "svc_predictions_df = pd.DataFrame({'index': index_list, 'RainTomorrow': svc_predictions})\n",
    "svc_predictions_df.to_csv('svc_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:373: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:374: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, 1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, 1, 1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "# Making CSV for adaboost predictions\n",
    "\n",
    "testX = cleantestdata(\"./weather_test.csv\")\n",
    "index_list = list(range(0, len(testX)))\n",
    "\n",
    "# AdaBoost for GNB\n",
    "gnb = GaussianNB()\n",
    "gnb_adaboost = AdaBoost(gnb)\n",
    "gnb_adaboost.fit(df)\n",
    "gnb_adaboost.predict(testX)\n",
    "gnb_ada_predictions = gnb_adaboost.predictions\n",
    "gnb_ada_predictions_df = pd.DataFrame({'index': index_list, 'RainTomorrow': gnb_ada_predictions})\n",
    "gnb_ada_predictions_df.to_csv('gnb_adaboost_predictions.csv')\n",
    "\n",
    "# AdaBoost for DT\n",
    "dt = DecisionTreeClassifier()\n",
    "dt_adaboost = AdaBoost(dt)\n",
    "dt_adaboost.fit(df)\n",
    "dt_adaboost.predict(testX)\n",
    "dt_ada_predictions = dt_adaboost.predictions\n",
    "dt_ada_predictions_df = pd.DataFrame({'index': index_list, 'RainTomorrow': dt_ada_predictions})\n",
    "dt_ada_predictions_df.to_csv('dt_adaboost_predictions.csv')\n",
    "\n",
    "# AdaBoost for Linear SVM\n",
    "svc = LinearSVC()\n",
    "svc_adaboost = AdaBoost(svc)\n",
    "svc_adaboost.fit(df)\n",
    "svc_adaboost.predict(testX)\n",
    "svc_ada_predictions = svc_adaboost.predictions\n",
    "svc_ada_predictions_df = pd.DataFrame({'index': index_list, 'RainTomorrow': svc_ada_predictions})\n",
    "svc_ada_predictions_df.to_csv('svc_adaboost_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

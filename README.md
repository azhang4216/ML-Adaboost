# Adaboost Algorithm from Scratch
An implementation of AdaBoost from scratch by Angela Zhang for Dartmouth College's CS74 Machine Learning Course taught by Professor V.S. Subrahmanian in 20F.

For any questions about the code or the proces, please email angela.zhang.23@dartmouth.edu.

# Tools & Libraries Used
This project was made with Python NumPy in Jupyter Notebook.

Libraries used include:
- pandas
- numpy
- matplotlib.pyplot
- sklearn
    - sklearn classifiers: DecisionTreeClassifier, GaussianNB, LinearSVC
    - preprocessing data: OrdinalEncoder, normalize, MinMaxScaler, SimpleImputer, train_test_split
    - accessing classifier quality: cross_val_score, classification_report, confusion_matrix, f1_score
- SMOTE (from imblearn's over_sampling)
- math

# Introduction & Motivation
As part of a class assignment, we were asked to implement Adaboost algorithm from scratch that can be used with any classifier. The 3 considered in particular for this assignment are Decision Trees, Gaussian Naive Bayes, and Linear SVC classifiers.

Given weather_test.csv, the training dataset, the classifying algorithm is then used to predict whether it will rain or not tomorrow for the test dataset Weather.csv. 

# Layout of Files & Folders
### datasets folder
- weather_test.csv: our training dataset
- Weather.csv: our testing dataset with which we generate predictions

### predictions folder
- dt_adaboost_predictions.csv: predictions generated by Decision Tree classifier with Adaboost using Weather.csv test dataset
- dt_predictions.csv: predictions generated by Decision Tree classifier without boosting using Weather.csv test dataset
- gnb_adaboost_predictions.csv: predictions generated by Gaussian Naive Bayes classifier with Adaboost using Weather.csv test dataset
- gnb_predictions.csv: predictions generated by Gaussian Naive Bayes classifier without boosting using Weather.csv test dataset
- svc_adaboost_predictions.csv: predictions generated by Linear SVC classifier with Adaboost using Weather.csv test dataset
- svc_predictions.csv: predictions generated by Linear SVC classifier without boosting using Weather.csv test dataset

### Adaboost.ipynb
The jupyter notebook file on which all the code is written. Commented code explains process clearly.

# Results
The quality of my Adaboost algorithm was evaluated by comparing the stand-alone F1 scores of Decision Trees, Gaussian Naive Bayes, and Linear SVC classifiers without boosting to its counterpart with boosting.

The following is a table of 10-fold Cross Validation F1 Scores of the results (rounded off to 3 decimal places):

| Base Classifier | Without Boosting | With Adaboost |
| ------------- |:-------------|:-----|
| Naive Bayes | 0.743 | 0.811 |
| Decision Trees | 0.806 | 0.875 |
| Linear SVM | 0.767 | 0.821 |

# Acknowledgements
Thanks to the following people / resources for making this project possible:
- Professor V.S. Subrahmanian for his support and information
- Statquest by Josh Starmer for additional research on implementation of Adaboost